{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "from time import time\n",
    "sys.dont_write_bytecode = True\n",
    "#__author__ = \"Saifuddin Abdullah\"\n",
    "\n",
    "#local imports\n",
    "from tools import fmin, Functions\n",
    "funcs_ = Functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of linear discriminant analysis for binary classification tasks.\n",
    "Any improvement or such suggestions will be honored. :-)\n",
    "provide features (x's) which can have any dimensions, and a set of 1d y's or observations.\n",
    "\"\"\"\n",
    "class LDA(object):\n",
    "    \"\"\"\"Linear discriminant analysis for multiclass/binary classification (x(i), y(i))\"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.funcs_ = funcs_\n",
    "        #verify the dimensions\n",
    "        if self.funcs_.verify_dimensions(x):\n",
    "            if len(x) == len(y):\n",
    "                self.len_all = len(x)\n",
    "                self.dmean_ = self.funcs_.mean_nm(x, axis=0)\n",
    "                self.std_ = self.funcs_.std_nm(x, axis=0)\n",
    "                self.x = x\n",
    "                self.y = y\n",
    "                self.separate_sets()\n",
    "            else:\n",
    "                sys.exit()\n",
    "        else:\n",
    "            print ('data dimensions are inaccurate..exiting..')\n",
    "            sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #--separating the datasets based on their associated classes or labels\n",
    "def separate_sets(self):\n",
    "        self.groups = {}\n",
    "        self.group_names = list(set(self.y))\n",
    "        if len(self.group_names) > 2:\n",
    "            print ('more than two classes provided...exiting')\n",
    "            sys.exit()\n",
    "        #putting all the samples in a regular order so that their\n",
    "        #grouping can be easier.\n",
    "        combined  = sorted(zip(self.x, self.y), key = lambda n: n[1])\n",
    "        #--doing val,key here because (x,y) was zipped\n",
    "        for val,key in combined:\n",
    "            if self.groups.has_key(key):\n",
    "                self.groups[key].append(val)\n",
    "            else:\n",
    "                self.groups[key] = []\n",
    "                self.groups[key].append(val)\n",
    "        #train on each group\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #--substracts global mean from the group point\n",
    "def substract_mean(self, group_point):\n",
    "        for i, a in enumerate(group_point):\n",
    "            group_point[i] = group_point[i] - self.mean_global[i]\n",
    "        \n",
    "        return group_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #--gets the covariance matrix for a dataset/group (t(x).x/len(x))\n",
    "def get_cov_matrix(self, matrix):\n",
    "        cov_mat = []\n",
    "        for i in zip(*matrix):\n",
    "            l = []\n",
    "            for e in zip(*matrix):\n",
    "                l.append(self.funcs_.dot(i, e)/len(matrix))\n",
    "            cov_mat.append(l)\n",
    "        return cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #--multiplies the length of dataset with each element of vector and\n",
    "    #--and divides by the total lenght of the dataset.\n",
    "def scalar_mult(self, scalar, vector, divisor):\n",
    "        new_vector = []\n",
    "        for  i, a in enumerate(vector):\n",
    "            new_vector.append((scalar*vector[i])/divisor)\n",
    "        return new_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #--adds two vectors linearly\n",
    "def sum_vectors(self, a, b):\n",
    "        return [g+h for g,h in zip(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #--calculates the global covariance matrix\n",
    "def get_global_cov(self, cov_matrices):\n",
    "        temp_cov = []\n",
    "        global_cov = []\n",
    "        for i, a in enumerate(cov_matrices):\n",
    "            l = []\n",
    "            for e, j in enumerate(cov_matrices[a]):\n",
    "                l.append(self.scalar_mult(self.lens[a], cov_matrices[a][e], self.len_all))\n",
    "            temp_cov.append(l)\n",
    "        for a,b in zip(*temp_cov):\n",
    "            global_cov.append(self.sum_vectors(a,b))\n",
    "        \n",
    "        return global_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #--processes the groups\n",
    "    #--finds mean for each of the data group and mean corrects it by substracting\n",
    "    #--global mean out of it and then finds covariance matrices for them.\n",
    "def train(self):\n",
    "        self.mean_sets = {}\n",
    "        covariance_sets = {}\n",
    "        self.lens ={}\n",
    "        self.probability_vector = {}\n",
    "        \n",
    "        self.mean_global = self.funcs_.mean_nm(self.x, axis=0)\n",
    "        for k, v in self.groups.iteritems():\n",
    "            self.lens[k] = len(self.groups[k])\n",
    "            self.probability_vector[k] = self.lens[k]/self.len_all\n",
    "            self.mean_sets[k] = self.funcs_.mean_nm(self.groups[k], axis=0)\n",
    "            #mean correcting each set i.e. set - global mean\n",
    "            self.groups[k] = map(self.substract_mean, self.groups[k])\n",
    "            covariance_sets[k] = self.get_cov_matrix(self.groups[k])\n",
    "        self.covariance_global = self.get_global_cov(covariance_sets)\n",
    "        #--inverse the global covariance matrix\n",
    "        self.covariance_global = self.funcs_.inv_(self.covariance_global)\n",
    "        #training completedelf.covariance_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #prediction or discrimnant function\n",
    "def predict(self, v, key_only=False):\n",
    "        predictions  = {}\n",
    "        for a in self.group_names:\n",
    "            predictions[a] = self.funcs_.dot(self.funcs_.prod_2(self.mean_sets[a], self.covariance_global), v) - (self.funcs_.dot(self.funcs_.prod_2(self.mean_sets[a], self.covariance_global), self.mean_sets[a])*0.5)+math.log(self.probability_vector[a])\n",
    "        if key_only:\n",
    "            return max(predictions, key=predictions.get)\n",
    "        else:\n",
    "            return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "A good way to approach multiclass LDA is to get the discriminant output pairwise i.e.\n",
    "form N(N-1)/2 pairs for the sample dataset, where N is the number of of classes involved\n",
    "and find classifications for each pair and then combine them to have the final output.\n",
    "\"\"\"\n",
    "class multiclass_LDA(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.funcs_ = funcs_\n",
    "        if self.funcs_.verify_dimensions(x):\n",
    "            if len(x) == len(y):\n",
    "                self.x  = x\n",
    "                self.y = y\n",
    "                self.process_sets()\n",
    "            else:\n",
    "                sys.exit()\n",
    "        else:\n",
    "            print ('data dimensions inaccurate..exiting.')\n",
    "            sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    #returns N(N-1)/2 pairs/combinations of the classes involved.\n",
    "def get_combinations(self, unique_labels):\n",
    "        g = []\n",
    "        for i, a in enumerate(unique_labels):\n",
    "            current_ = unique_labels[i]\n",
    "            for e, b in enumerate(unique_labels):\n",
    "                if e > i:\n",
    "                    g.append([unique_labels[i], unique_labels[e]])\n",
    "        return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #for separating data based on classes (not used any more)\n",
    "def separate_data(self, combined):\n",
    "        #sort all the classes so that no fuss is there\n",
    "        combined = sorted(combined, key=lambda n: n[1])\n",
    "        for i, a in enumerate(combined):\n",
    "            self.separated_features[combined[i][1]].append(combined[i][0])\n",
    "            self.separated_labels[combined[i][1]].append(combined[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #returns data based on the given binary class combination (a,b)\n",
    "def get_x(self, current_):\n",
    "        result = []\n",
    "        for a,b in zip(self.x, self.y):\n",
    "            if b in current_:\n",
    "                result.append(copy.deepcopy(a))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #returns labels based on the given binary class combination (a, b)\n",
    "def get_y(self, current_):\n",
    "        result = []\n",
    "        for i, a in enumerate(self.y):\n",
    "            if self.y[i] in current_:\n",
    "                result.append(copy.deepcopy(self.y[i]))\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #processes each set of classifiers\n",
    "def process_sets(self):\n",
    "        self.unique_labels = list(set(self.y))\n",
    "        #self.separated_features = dict([(k, []) for k in self.unique_labels])\n",
    "        #self.separated_labels = dict([(k, []) for k in self.unique_labels])\n",
    "        #self.separate_data(zip(self.x, self.y))\n",
    "        self.combinations = self.get_combinations(self.unique_labels)\n",
    "        self.classifiers = {}\n",
    "\n",
    "        #training a classifier for each pair\n",
    "        for a in self.combinations:\n",
    "            import time as qt\n",
    "            x_ = []\n",
    "            y_ = []\n",
    "            current_ = a\n",
    "            x_ = self.get_x(current_)\n",
    "            y_ = self.get_y(current_)\n",
    "            self.classifiers[tuple(a)] = LDA(x_,y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #return predictions from each classifier\n",
    "def predict(self, v, key_only=True):\n",
    "        candidates = dict([(k, 0) for k in self.unique_labels])\n",
    "        t = []\n",
    "        for key, value in self.classifiers.iteritems():\n",
    "            t.append(self.classifiers[key].predict(v))\n",
    "        for a in t:\n",
    "            winner_ = max(a, key=a.get)\n",
    "            candidates[winner_] += 1\n",
    "\n",
    "        if key_only:\n",
    "            return max(candidates, key=candidates.get)\n",
    "        else:\n",
    "            return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
